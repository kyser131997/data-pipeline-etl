# Architecture Technique : Pipeline ETL NYC Taxi

Ce document propose une immersion technique dans la conception, le flux de donn√©es et les d√©tails d'impl√©mentation du pipeline ETL NYC Yellow Taxi.

## üìê Conception du Syst√®me

L'architecture est construite autour du mod√®le **ELT (Extract-Load-Transform)**, s√©parant l'ingestion des donn√©es de leur traitement.

```mermaid
graph TD
    subgraph "Sources Externes"
        NYC["NYC Open Data (Cloudfront)"]
    end

    subgraph "Couche d'Ingestion (Python + Cloud Storage)"
        DS["download_taxi_data.py"]
        GCS["GCS : Data Lake Brut (Parquet)"]
    end

    subgraph "Couche de Traitement (BigQuery)"
        LS["load_raw_trips_data.py"]
        RT["BigQuery : Tables Brutes (Raw)"]
        TS["transform_trips_data.py"]
        TT["BigQuery : Tables Transform√©es"]
    end

    subgraph "Orchestration"
        AF["Apache Airflow (Cloud Composer)"]
    end

    subgraph "Analyse & Consommation"
        NB["Notebooks Jupyter"]
        ML["Mod√®les BigQuery ML"]
    end

    NYC --> DS
    DS --> GCS
    GCS --> LS
    LS --> RT
    RT --> TS
    TS --> TT
    TT --> NB
    TT --> ML
    AF -.->|"Planifie & D√©clenche"| DS
    AF -.->|"Planifie & D√©clenche"| LS
    AF -.->|"Planifie & D√©clenche"| TS
```

## üîå Composants du Pipeline

### 1. Extraction (`download_taxi_data.py`)
*   **Source :** Donn√©es d'enregistrement des trajets de la NYC Taxi & Limousine Commission (TLC).
*   **Format :** Parquet.
*   **Logique :** Parcourt les ann√©es (√† partir de 2020) et les mois. Le script v√©rifie la pr√©sence des fichiers sur GCS avant le t√©l√©chargement pour garantir l'idempotence et √©viter une utilisation redondante de la bande passante.
*   **Journalisation :** Les journaux (logs) sont diffus√©s et t√©l√©charg√©s vers `gs://{bucket}/from-git/logs/` √† la fin de l'ex√©cution.

### 2. Chargement (`load_raw_trips_data.py`)
*   **Processus :** Charge les donn√©es de GCS vers BigQuery.
*   **Staging :** Utilise une table temporaire (`_temp`) avec `autodetect=True` pour g√©rer l'ingestion initiale. Cela permet √† BigQuery de g√©rer l'√©volution potentielle du sch√©ma avec souplesse.
*   **Ingestion Finale :** Ex√©cute une requ√™te `INSERT INTO` pour d√©placer les donn√©es de la table temporaire vers la table brute principale, en convertissant explicitement `passenger_count` en `FLOAT64` pour maintenir la coh√©rence entre les diff√©rentes versions des fichiers sources.

### 3. Transformation (`transform_trips_data.py`)
*   **Impl√©mentation :** SQL BigQuery pur.
*   **Logique de Nettoyage :**
    ```sql
    WHERE passenger_count > 0
      AND trip_distance > 0
      AND payment_type != 6 -- Filtrage des annulations/erreurs
      AND total_amount > 0
    ```
*   **R√©sultat :** Une table hautement optimis√©e pr√™te pour l'analyse en aval.

### 4. Orchestration (`elt_dag_pipeline.py`)
*   **ID du DAG :** `elt_pipeline_nyc_taxi`
*   **Planification :** `0 23 * * 5` (Chaque vendredi √† 23h).
*   **Capteur (Sensor) :** Inclut un `TimeDeltaSensor` pour contr√¥ler pr√©cis√©ment le moment de l'ex√©cution (dernier vendredi du mois).
*   **Interop√©rabilit√© :** Utilise le `BashOperator` pour r√©cup√©rer les scripts sur GCS et les ex√©cuter dans l'environnement du worker Airflow.

## üîí S√©curit√© & Bonnes Pratiques

*   **Gestion des Identit√©s :** Utilisation des comptes de service Google Cloud pour une authentification s√©curis√©e et sans cl√© entre Airflow et GCS/BigQuery.
*   **Persistance des Journaux :** Tous les journaux des scripts sont conserv√©s sur GCS pour l'audit historique et le d√©pannage.
*   **Optimisation des Co√ªts :** Exploite le format Parquet (colonnaire) et la logique `WRITE_TRUNCATE`/`WRITE_APPEND` de BigQuery pour minimiser les co√ªts de stockage et de calcul.
