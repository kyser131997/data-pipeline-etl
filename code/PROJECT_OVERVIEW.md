# Projet Portfolio : Pipeline ETL Automatis√© NYC Taxi

## üåü R√©sum√© Ex√©cutif

Ce projet met en ≈ìuvre un pipeline de donn√©es enti√®rement automatis√© sur **Google Cloud Platform** pour traiter les enregistrements de trajets des taxis jaunes de la ville de New York (NYC Yellow Taxi). En exploitant des services cloud natifs tels que **BigQuery**, **Cloud Storage** et **Cloud Composer (Airflow)**, j'ai construit un syst√®me √©volutif qui transforme des millions de points de donn√©es brutes en un format structur√©, pr√™t pour l'analyse avanc√©e et le Machine Learning.

## üéØ Cas d'Utilisation et Objectifs

Dans le secteur du transport urbain, les d√©cisions bas√©es sur les donn√©es sont cruciales pour optimiser la gestion de la flotte et les strat√©gies de tarification. Les donn√©es brutes des taxis de NYC sont volumineuses et se pr√©sentent sous diff√©rents formats au fil du temps.

**Mes objectifs √©taient les suivants :**
1.  **Automatiser l'ingestion :** √âliminer la collecte manuelle de donn√©es en planifiant des t√©l√©chargements mensuels.
2.  **Assurer l'√©volutivit√© :** Utiliser une infrastructure cloud capable de g√©rer des ensembles de donn√©es massifs sans d√©gradation des performances.
3.  **Qualit√© des donn√©es :** Mettre en ≈ìuvre une logique de transformation pour filtrer les anomalies (ex: trajets sans passagers, distances n√©gatives).
4.  **Permettre les pr√©dictions :** Cr√©er un jeu de donn√©es "Gold" optimis√© pour l'entra√Ænement de mod√®les ML afin de pr√©dire les co√ªts des trajets ou la demande.

## üõ†Ô∏è Le Parcours Technique

### 1. Le Lac de Donn√©es Brut (GCS)
La premi√®re √©tape implique un orchestrateur Python qui r√©cup√®re les fichiers Parquet depuis le portail NYC Open Data. Ces fichiers sont stock√©s dans **Google Cloud Storage**, servant de "Data Lake" immuable. Cela garantit que nous disposons toujours des donn√©es sources originales pour un retraitement si n√©cessaire.

### 2. L'Entrep√¥t de Donn√©es (BigQuery)
J'ai con√ßu un processus de chargement √† deux niveaux dans **BigQuery** :
-   **Zone Raw (brute) :** Les donn√©es sont charg√©es telles quelles dans des tables d'atterrissage.
-   **Zone Refined (raffin√©e) :** √Ä l'aide de transformations SQL, je nettoie les donn√©es ‚Äî en g√©rant les conversions de types (comme `passenger_count` de float √† int) et en supprimant les enregistrements erron√©s.

### 3. Orchestration avec Apache Airflow
L'ensemble du processus est g√©r√© par un **DAG Airflow**. Cela offre une interface visuelle pour surveiller la sant√© du pipeline, g√©rer les tentatives automatiques (retries) et planifier le flux de travail pour qu'il s'ex√©cute le dernier vendredi de chaque mois, garantissant ainsi que les derni√®res donn√©es sont toujours trait√©es.

## üìà Impact et R√©sultats

*   **Efficacit√© :** R√©duction de 90 % du temps de pr√©paration des donn√©es gr√¢ce √† l'automatisation.
*   **Fiabilit√© :** Mise en ≈ìuvre d'une logique de chargement "idempotente" qui emp√™che les entr√©es de donn√©es en double, m√™me si une t√¢che est red√©marr√©e.
*   **Pr√™t pour l'IA :** La table finale est directement compatible avec **BigQuery ML**, permettant le d√©veloppement imm√©diat de mod√®les pr√©dictifs sans ETL suppl√©mentaire.

## üí° Apprentissages Cl√©s

La r√©alisation de ce projet m'a permis d'approfondir mon expertise en :
-   **Orchestration de flux de travail complexes** √† travers plusieurs services cloud.
-   **Conception de sch√©mas SQL efficaces** dans un environnement d'entrep√¥t de donn√©es serverless.
-   **Mise en ≈ìuvre des meilleures pratiques** pour l'ing√©nierie de donn√©es, telles que la journalisation, la gestion des erreurs et le chargement incr√©mentiel.
